{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBT-net Model Loading Notebook\n",
    "\n",
    "This notebook demonstrates loading pretrained weights for segmentation and classification models for the GBT-net project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.networks.nets import swin_unetr\n",
    "from monai.networks.nets.swin_unetr import SwinUNETR\n",
    "from gbt_net import SwinTransformer_new, PatchMergingV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function\n",
    "Define a helper to rename keys in the checkpoint state dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_weight_key(state_dict, source_key='module.', target_key=''):\n",
    "    print(\"Tag '\", source_key, \"' found in state dict - fixing to \", target_key)\n",
    "    for key in list(state_dict.keys()):\n",
    "        if source_key in key:\n",
    "            state_dict[key.replace(source_key, target_key)] = state_dict.pop(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint\n",
    "Load the pretrained checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/path/to/your/directory/gbt_net_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model and load state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation model\n",
    "swin_unetr.MERGING_MODE = {\"mergingv3\": PatchMergingV3}\n",
    "segmentation_model = SwinUNETR(\n",
    "    img_size=(128, 128, 128),\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    feature_size=48,\n",
    "    downsample=\"mergingv3\",\n",
    "    use_v2=True\n",
    ")\n",
    "\n",
    "missing_keys, unexpected_keys = segmentation_model.load_state_dict(checkpoint, strict=False)\n",
    "print(missing_keys)\n",
    "print(unexpected_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification model\n",
    "classification_model = SwinTransformer_new(in_chans=1, embed_dim=48, window_size=(7, 7, 7), \n",
    "                            patch_size=(2, 2, 2), depths=(2, 2, 2, 2), num_heads=(3, 6, 12, 24), downsample=\"mergingv3\", use_v2=True)\n",
    "\n",
    "change_weight_key(checkpoint, 'swinViT.', '')\n",
    "\n",
    "\n",
    "missing_keys, unexpected_keys = classification_model.load_state_dict(checkpoint, strict=False)\n",
    "print(missing_keys)\n",
    "print(unexpected_keys)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
